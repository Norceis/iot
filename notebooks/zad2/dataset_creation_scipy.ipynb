{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-19T09:10:34.129023Z",
     "end_time": "2023-05-19T09:10:34.182934Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas\n",
    "import h5py\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import skimage.io\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "\n",
    "\n",
    "RAWDATA_PATH = '..\\data\\Glosy_zbior'\n",
    "SAVE_PATH = '..\\data\\\\'\n",
    "\n",
    "peoples = ['Adrian',\n",
    "           'Bartek',\n",
    "           'Damian',\n",
    "           'Ewelina',\n",
    "           'Hubert',\n",
    "           'jakub',\n",
    "           'Kamil',\n",
    "           'Kasia',\n",
    "           'Kuba',\n",
    "           'Lukasz',\n",
    "           'Mariusz',\n",
    "           'Mikolaj',\n",
    "           'oskar',\n",
    "           'patryk',\n",
    "           'Pawel',\n",
    "           'przemek',\n",
    "           'Rafal',\n",
    "           'szymon']\n",
    "\n",
    "words = ['background',\n",
    "         'close',\n",
    "         'door',\n",
    "         'down',\n",
    "         'go',\n",
    "         'home',\n",
    "         'left',\n",
    "         'light',\n",
    "         'no',\n",
    "         'off',\n",
    "         'on',\n",
    "         'open',\n",
    "         'right',\n",
    "         'shutdown',\n",
    "         'silence',\n",
    "         'speech',\n",
    "         'stop',\n",
    "         'unknown',\n",
    "         'up',\n",
    "         'windows',\n",
    "         'yes',\n",
    "         ]\n",
    "\n",
    "def save_to_pickle(path, group_name, samples):\n",
    "    filename = path + '\\\\' + group_name + '.pickle'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(samples, f)\n",
    "\n",
    "    # try:\n",
    "    #     with h5py.File(path, 'r+') as hdf:\n",
    "    #         samples_group = hdf.create_group(group_name +'_samples')\n",
    "    #\n",
    "    #         for i, arr in enumerate(samples):\n",
    "    #             samples_group.create_dataset(str(i), data=arr)\n",
    "    #\n",
    "    #         hdf.close()\n",
    "    # except:\n",
    "    #     with h5py.File(path, 'w') as hdf:\n",
    "    #         samples_group = hdf.create_group(group_name +'_samples')\n",
    "    #\n",
    "    #         for i, arr in enumerate(samples):\n",
    "    #             samples_group.create_dataset(str(i), data=arr)\n",
    "    #\n",
    "    #         hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "labels = commands"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def mel_from_file(sample_rate, audio_data):\n",
    "    pre_emphasis = 0.97\n",
    "    emphasized_audio = np.append(audio_data[0], audio_data[1:] - pre_emphasis * audio_data[:-1])\n",
    "    frame_length = 0.025  # Length of each frame in seconds\n",
    "    frame_shift = 0.01  # Shift between consecutive frames in seconds\n",
    "    fft_size = 512  # Size of the FFT (Fast Fourier Transform)\n",
    "    samples_per_frame = int(frame_length * sample_rate)\n",
    "    samples_per_shift = int(frame_shift * sample_rate)\n",
    "    window = signal.hamming(samples_per_frame)\n",
    "    num_frames = 1 + int((len(emphasized_audio) - samples_per_frame) / samples_per_shift)\n",
    "    frames = np.zeros((num_frames, samples_per_frame))\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        start = i * samples_per_shift\n",
    "        frames[i] = emphasized_audio[start : start + samples_per_frame] * window\n",
    "    spectra = np.abs(np.fft.rfft(frames, n=fft_size))\n",
    "    power_spectra = spectra ** 2\n",
    "    power_spectra_db = 10 * np.log10(1 + power_spectra)\n",
    "\n",
    "    return power_spectra_db\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T09:10:34.827573Z",
     "end_time": "2023-05-19T09:10:34.846987Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1134 [00:00<?, ?it/s]C:\\Users\\cubix\\AppData\\Local\\Temp\\ipykernel_1044\\1372660600.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample = mel_from_file(*wav.read(root_dir + '\\\\' + file))\n",
      "100%|██████████| 1134/1134 [00:04<00:00, 274.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# nonaugmented\n",
    "spectros = []\n",
    "labels = []\n",
    "samples = []\n",
    "for root_dir, cur_dir, files in os.walk(RAWDATA_PATH):\n",
    "    for file in tqdm(files):\n",
    "        temp = file.split('_')\n",
    "        name = temp[0]\n",
    "        command = temp[1]\n",
    "        sample = mel_from_file(*wav.read(root_dir + '\\\\' + file))\n",
    "        samples.append((sample, command, name))\n",
    "\n",
    "save_to_pickle(path=SAVE_PATH, group_name='commands_no_aug', samples=samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T09:10:35.557322Z",
     "end_time": "2023-05-19T09:10:41.070179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1134 [00:00<?, ?it/s]C:\\Users\\cubix\\AppData\\Local\\Temp\\ipykernel_1044\\1405655812.py:13: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sample_rate, audio_data = wav.read(root_dir + '\\\\' + file)\n",
      "100%|██████████| 1134/1134 [02:36<00:00,  7.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# augmented\n",
    "augmented = []\n",
    "\n",
    "NOISE_RANGE = (0, 2)\n",
    "pitch_shift_ranges = np.linspace(-2.5, 2.5, num=3)\n",
    "time_shift_ranges = np.linspace(0.8, 1.2, num=3)\n",
    "\n",
    "for root_dir, cur_dir, files in os.walk(RAWDATA_PATH):\n",
    "    for file in tqdm(files):\n",
    "        temp = file.split('_')\n",
    "        name = temp[0]\n",
    "        command = temp[1]\n",
    "        sample_rate, audio_data = wav.read(root_dir + '\\\\' + file)\n",
    "        sample = mel_from_file(sample_rate, audio_data)\n",
    "        augmented.append((sample, command, name))\n",
    "        for _ in range(10):\n",
    "            noised_sample = audio_data * np.random.uniform(0, 2, size=audio_data.shape)\n",
    "            sample = mel_from_file(sample_rate, noised_sample)\n",
    "            augmented.append((sample, command, name))\n",
    "\n",
    "save_to_pickle(path=SAVE_PATH, group_name='commands_aug', samples=samples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-19T09:31:02.327319Z",
     "end_time": "2023-05-19T09:33:47.855923Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "labels = persons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1134/1134 [00:03<00:00, 323.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# nonaugmented\n",
    "spectros = []\n",
    "labels = []\n",
    "\n",
    "for root_dir, cur_dir, files in os.walk(RAWDATA_PATH):\n",
    "    for file in tqdm(files):\n",
    "        for person in peoples:\n",
    "            if str(person.lower() + '_') in file.lower():\n",
    "                labels.append(person)\n",
    "                y, sr = librosa.load(root_dir + '\\\\' + file)\n",
    "                sample = librosa.stft(y)\n",
    "                sample = librosa.amplitude_to_db(np.abs(sample), ref=np.max)\n",
    "                spectros.append(sample)\n",
    "                break\n",
    "\n",
    "save_to_h5(path=SAVE_PATH, group_name='peoples_no_aug', spectros=spectros, labels=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T11:06:29.683452900Z",
     "start_time": "2023-05-18T11:06:22.704770900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1134/1134 [03:52<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# augmented\n",
    "spectros = []\n",
    "labels = []\n",
    "\n",
    "NOISE_RANGE = (0, 2)\n",
    "pitch_shift_ranges = np.linspace(-2.5, 2.5, num=3)\n",
    "time_shift_ranges = np.linspace(0.8, 1.2, num=3)\n",
    "\n",
    "for root_dir, cur_dir, files in os.walk(RAWDATA_PATH):\n",
    "    for file in tqdm(files):\n",
    "        for person in peoples:\n",
    "            if str(person.lower() + '_') in file.lower():\n",
    "                y, sr = librosa.load(root_dir + '\\\\' + file)\n",
    "                for pitch_shift in pitch_shift_ranges:\n",
    "                    for time_shift in time_shift_ranges:\n",
    "                        sample = librosa.effects.pitch_shift(y, sr=sr, n_steps=pitch_shift)\n",
    "                        sample = librosa.effects.time_stretch(sample, rate=time_shift)\n",
    "                        sample = sample * np.random.uniform(*NOISE_RANGE, size=sample.shape)\n",
    "                        sample = librosa.stft(sample)\n",
    "                        sample = librosa.amplitude_to_db(np.abs(sample), ref=np.max)\n",
    "                        spectros.append(sample)\n",
    "                        labels.append(person)\n",
    "                break\n",
    "\n",
    "save_to_h5(path=SAVE_PATH, group_name='peoples_aug', spectros=spectros, labels=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T11:12:10.886857200Z",
     "start_time": "2023-05-18T11:07:26.290376500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(spectros)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('E:\\iot\\data\\spectrograms.h5', 'r') as hdf:\n",
    "    print(hdf['peoples_aug_labels']['10'][()].decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T10:02:14.532146900Z",
     "start_time": "2023-05-18T10:02:14.515149400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# counter_object = Counter(labels_list)\n",
    "# keys = counter_object.keys()\n",
    "# print(keys, counter_object.values())\n",
    "# len(labels_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
